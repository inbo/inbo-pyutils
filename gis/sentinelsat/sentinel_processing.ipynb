{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing sentinel-2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA MANAGMENT and PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import zipfile\n",
    "import shutil\n",
    "import more_itertools\n",
    "from more_itertools import unique_everseen\n",
    "\n",
    "# import gui tkinter\n",
    "from tkinter import Tk\n",
    "import tkinter.filedialog as tkfd\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(message)s', level='INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input and output directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **tkinter GUI** is loaded:\n",
    "- to locate and select the **input zipfiles**,\n",
    "- to define the **output directory**, and\n",
    "- to locate a GeoJSON file, defining the **bouding box of Flanders**.\n",
    "\n",
    "The tkinter input is printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following files have been selected for processing:\n",
      "- C:/WERKMAP/Anaconda/sentinelsat/downloaded_datasets/S2A_OPER_PRD_MSIL1C_PDMC_20160827T181148_R008_V20160826T104022_20160826T104023.zip\n",
      "- C:/WERKMAP/Anaconda/sentinelsat/downloaded_datasets/S2A_OPER_PRD_MSIL1C_PDMC_20160827T195703_R008_V20160826T104022_20160826T104023.zip\n",
      " \n",
      "The selected output folder is:\n",
      "- C:/SS\n",
      " \n",
      "The selected bounding box is located at:\n",
      "- C:/WERKMAP/Anaconda/sentinelsat/geojson/footprint_flanders_geojson.geojson\n"
     ]
    }
   ],
   "source": [
    "# tkinter GUI\n",
    "root = Tk()\n",
    "input_zip_files = tkfd.askopenfilenames(title = \"Select input dataset (zipfiles)\", \n",
    "                                             initialdir = \"C:/\", \n",
    "                                             filetypes = ((\"zipfile\", \"*.zip\"),(\"all files\", \"*.*\")))\n",
    "output_dir = tkfd.askdirectory(title = \"Select output folder\", initialdir = \"C:/\")\n",
    "bounding_box_flanders = tkfd.askopenfilename(title = \"Select input GeoJSON, defining the bounding box of Flanders\", \n",
    "                                             initialdir = \"C:/\", \n",
    "                                             filetypes = ((\"GeoJSON\", \"*.geojson\"),(\"all files\", \"*.*\")))\n",
    "root.destroy()\n",
    "\n",
    "# print statements: the tkinter input is printed to the console\n",
    "print(\"The following files have been selected for processing:\")\n",
    "for zip_file in input_zip_files:\n",
    "    print(\"-\", zip_file)\n",
    "print(\" \")\n",
    "print(\"The selected output folder is:\")\n",
    "print(\"-\", output_dir)\n",
    "print(\" \")\n",
    "print(\"The selected bounding box is located at:\")\n",
    "print(\"-\", bounding_box_flanders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REVIEW of the selected input zipfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output directory is checked for what has been done in the past. Files with a date that already exists in the output directory will be removed from the selection. An overview is printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input zip files are validated:\n",
      "- C:/WERKMAP/Anaconda/sentinelsat/downloaded_datasets/S2A_OPER_PRD_MSIL1C_PDMC_20160827T181148_R008_V20160826T104022_20160826T104023.zip will be processed.\n",
      "- C:/WERKMAP/Anaconda/sentinelsat/downloaded_datasets/S2A_OPER_PRD_MSIL1C_PDMC_20160827T195703_R008_V20160826T104022_20160826T104023.zip will be processed.\n",
      " \n",
      "SUMMARY:\n",
      "---\n",
      "The following date(s) already exist in the output folder:\n",
      "- None\n",
      "The corresponding 0 file(s) were dropped from the selection.\n",
      " \n",
      "File(s) with the following dates will be processed:\n",
      "- 20160826\n",
      "The corresponding 2 file(s) will be processed:\n",
      "- C:/WERKMAP/Anaconda/sentinelsat/downloaded_datasets/S2A_OPER_PRD_MSIL1C_PDMC_20160827T181148_R008_V20160826T104022_20160826T104023.zip\n",
      "- C:/WERKMAP/Anaconda/sentinelsat/downloaded_datasets/S2A_OPER_PRD_MSIL1C_PDMC_20160827T195703_R008_V20160826T104022_20160826T104023.zip\n"
     ]
    }
   ],
   "source": [
    "validated_zip_files = []\n",
    "to_process = 0\n",
    "to_process_dates = []\n",
    "no_action = 0\n",
    "no_action_dates = []\n",
    "\n",
    "print(\"The input zip files are validated:\")\n",
    "for input_zip_file in input_zip_files:\n",
    "    date = input_zip_file[-19:-11]\n",
    "    if date not in os.listdir(output_dir):\n",
    "        validated_zip_files.append(input_zip_file)\n",
    "        to_process = to_process + 1\n",
    "        to_process_dates.append(date)\n",
    "        print(\"-\", input_zip_file, \"will be processed.\")\n",
    "    else:\n",
    "        no_action = no_action + 1\n",
    "        no_action_dates.append(date)\n",
    "        print(\"- WARNING: An output folder with date\", date, \"already exist.\", input_zip_file, \"is dropped from the selection.\")\n",
    "        \n",
    "to_process_dates = list(unique_everseen(to_process_dates))\n",
    "no_action_dates = list(unique_everseen(no_action_dates))\n",
    "\n",
    "# print statements\n",
    "print(\" \")\n",
    "print(\"SUMMARY:\")\n",
    "print(\"---\")\n",
    "print(\"The following date(s) already exist in the output folder:\")\n",
    "if no_action == 0:\n",
    "    print(\"- None\")\n",
    "else:\n",
    "    for no_action_date in no_action_dates:\n",
    "        print(\"-\", no_action_date)\n",
    "print(\"The corresponding\", no_action, \"file(s) were dropped from the selection.\")\n",
    "print(\" \")\n",
    "print(\"File(s) with the following dates will be processed:\")\n",
    "if to_process == 0:\n",
    "    print(\"- None\")\n",
    "else:\n",
    "    for to_process_date in to_process_dates:\n",
    "        print(\"-\", to_process_date)\n",
    "print(\"The corresponding\", to_process, \"file(s) will be processed:\")        \n",
    "for validated_zip_file in validated_zip_files:\n",
    "    print(\"-\", validated_zip_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNZIP the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentinel data is donwloaded and stored as a zipfile. A temporary folder is created in the output directory, named \"tempUZ\" where the zipfiles will be unpacked and accessed for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:/WERKMAP/Anaconda/sentinelsat/downloaded_datasets/S2A_OPER_PRD_MSIL1C_PDMC_20160827T181148_R008_V20160826T104022_20160826T104023.zip started...\n",
      "Extracting C:/WERKMAP/Anaconda/sentinelsat/downloaded_datasets/S2A_OPER_PRD_MSIL1C_PDMC_20160827T181148_R008_V20160826T104022_20160826T104023.zip done!\n",
      "Extracting C:/WERKMAP/Anaconda/sentinelsat/downloaded_datasets/S2A_OPER_PRD_MSIL1C_PDMC_20160827T195703_R008_V20160826T104022_20160826T104023.zip started...\n",
      "Extracting C:/WERKMAP/Anaconda/sentinelsat/downloaded_datasets/S2A_OPER_PRD_MSIL1C_PDMC_20160827T195703_R008_V20160826T104022_20160826T104023.zip done!\n",
      "All datasets unpacked. Unzipping finished!\n"
     ]
    }
   ],
   "source": [
    "# A temporary folder is created in the output directory, named \"tempUZ\", where the files will be unzipped.\n",
    "extraction_zip_dir = output_dir + \"/tempUZ/\"\n",
    "if not os.path.isdir(output_dir + \"/tempUZ/\"):\n",
    "    os.mkdir(output_dir + \"/tempUZ/\")\n",
    "    \n",
    "# unzip files\n",
    "for validated_zip_file in validated_zip_files:\n",
    "    print(\"Extracting\", validated_zip_file, \"started...\")\n",
    "    z = zipfile.ZipFile(validated_zip_file)\n",
    "    z.extractall(extraction_zip_dir)\n",
    "    print(\"Extracting\", validated_zip_file, \"done!\")\n",
    "\n",
    "# print statement\n",
    "print(\"All datasets unpacked. Unzipping finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DELETE useless data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only granules within or partially within the bounding box of Flanders are kept. All other granules are deleted.\n",
    "\n",
    "Eight granules overlap with the Flanders bounding box: \n",
    "* T31UDT - T31UET - T31UFT - T31UGT\n",
    "* T31UDS - T31UES - T31UFS - T31UGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start data management procedure...\n"
     ]
    }
   ],
   "source": [
    "print(\"Start data management procedure...\")\n",
    "# Eight granules overlap with the Flanders bounding box\n",
    "selected_granules = [\"T31UDS\", \"T31UES\", \"T31UFS\", \"T31UGS\", \"T31UDT\", \"T31UET\", \"T31UFT\", \"T31UGT\"]\n",
    "# select folders with granules overlapping the bounding box of Flanders...\n",
    "selected_folders =[]\n",
    "for folder in glob(os.path.join(extraction_zip_dir, \"**\", \"*/GRANULE/*\"), recursive=True):\n",
    "    for granule in selected_granules:\n",
    "        if granule in folder:\n",
    "            selected_folders.append(folder)\n",
    "# and delete the other granules.\n",
    "for folder in glob(os.path.join(extraction_zip_dir, \"**\", \"*/GRANULE/*\"), recursive=True):\n",
    "    if folder not in selected_folders:\n",
    "        shutil.rmtree(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REARRANGE data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is rearranged and grouped by date to easily allow mosaicing of imagery. This happens in three steps:\n",
    "- A temporary \"processing\" folder, named \"P\", is created. \n",
    "- The data is grouped by date and moved to the processing folder \"P\".\n",
    "- The now empty temporary zip directory \"tempUZ\" is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory C:/SS/P created.\n",
      "Data moved to C:/SS/P\n",
      "Data management procedure finished.\n"
     ]
    }
   ],
   "source": [
    "# A temporary \"processing\" folder, named \"P\", is created. \n",
    "processing_dir = output_dir + \"/\" + \"P\"\n",
    "if not os.path.isdir(processing_dir):\n",
    "    os.mkdir(processing_dir)\n",
    "print(\"Processing directory\", processing_dir, \"created.\")\n",
    "    \n",
    "# The data is grouped by date and moved to the processing folder.\n",
    "for filename in os.listdir(extraction_zip_dir):\n",
    "    date = filename[-20:-12]\n",
    "    date_folder = processing_dir + \"/\" + date\n",
    "    if not os.path.isdir(date_folder):\n",
    "        os.mkdir(date_folder)\n",
    "    folder = extraction_zip_dir + \"/\" + filename\n",
    "    shutil.move(src = folder, dst = date_folder)\n",
    "\n",
    "print(\"Data moved to\", processing_dir)\n",
    "    \n",
    "# The now empty temporary zip directory \"tempUZ\" is deleted.\n",
    "shutil.rmtree(extraction_zip_dir)\n",
    "\n",
    "print(\"Data management procedure finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GDAL data files not located, GDAL_DATA not set\n",
      "PROJ data files not located, PROJ_LIB not set\n"
     ]
    }
   ],
   "source": [
    "import rsgislib\n",
    "from rsgislib import imageutils, RSGISPyUtils\n",
    "import osgeo\n",
    "from osgeo import gdal, osr, ogr\n",
    "from rasterstats import zonal_stats\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enable GDAL/OGR exceptions and set GDAL data\n",
    "gdal.UseExceptions()\n",
    "osgeo.gdal.SetConfigOption(\"GDAL_DATA\", \"C:/Users/jeroen.dereu@inbo.be/Software/gdal-2.1.3/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following folders will be processed:\n",
      "- C:/SS/P/20160826/\n"
     ]
    }
   ],
   "source": [
    "#listdir checken\n",
    "folders_to_be_processed = []\n",
    "for date_folder in os.listdir(processing_dir): \n",
    "    folders_to_be_processed.append(processing_dir + \"/\" + date_folder + \"/\")\n",
    "\n",
    "print(\"The following folders will be processed:\")\n",
    "for date_folder in folders_to_be_processed:\n",
    "    print(\"-\", date_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERSION: JP2 to GeoTiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are converted from the JP2 to the GeoTiff fileformat.\n",
    "- Images are converted one by one. This means one input image results in one output image.\n",
    "- Coordinates are transformed from EPSG:32631 to EPSG:4326.\n",
    "- The Geotiffs are written to a new subfolder, named \"ind_tifs\".\n",
    "- The original filename is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start converting imagery in C:/SS/P/20160826/ : JP2 to GeoTiff...\n",
      "Finished converting imagery in C:/SS/P/20160826/ : JP2 to GeoTiff!\n",
      "All datasets converted. Conversion from JP2 to GeoTiff finished!\n"
     ]
    }
   ],
   "source": [
    "for date_folder in folders_to_be_processed:\n",
    "    print(\"Start converting imagery in\", date_folder, \": JP2 to GeoTiff...\")\n",
    "    for path in glob(os.path.join(date_folder, \"**\", \"*.jp2\"), recursive=True):\n",
    "        basename = os.path.basename(path)\n",
    "        filename, file_extention = os.path.splitext(basename)\n",
    "        if not os.path.isdir(date_folder + \"/ind_tifs\"):\n",
    "            os.mkdir(date_folder + \"/ind_tifs\")\n",
    "        output_folder = date_folder + \"/ind_tifs/\"\n",
    "        output_file = output_folder + filename + \".tif\"\n",
    "        gdal.Warp(destNameOrDestDS = output_file, \n",
    "                  srcDSOrSrcDSTab = path, \n",
    "                  dstSRS = \"EPSG:4326\", \n",
    "                  srcSRS = \"EPSG:32631\")\n",
    "    print(\"Finished converting imagery in\", date_folder, \": JP2 to GeoTiff!\")\n",
    "print(\"All datasets converted. Conversion from JP2 to GeoTiff finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOSAIC individual bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mosaic of the available imagery per day for each of the 13 bands is created. Also one overview mosaic is produced.\n",
    "- For each day, 14 images (GeoTiff) are created.\n",
    "- The output coordinatesystem is EPSG:4326.\n",
    "- The mosaic is cropped to the bounding box Flanders.\n",
    "- The mosaics are written to a new subfolder, named \"merged_bands\".\n",
    "- The filename consists of the date and the bandnumber (e.g. 20160720_B05.tif).\n",
    "\n",
    "\n",
    "\n",
    "                        Detailed overview of the 13 bands.\n",
    "|Band name\t|Resolution (m)\t|Central wavelength (nm)\t|Band width (nm)\t|Purpose\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|B01\t|60\t|443\t|20\t|Aerosol detection|\n",
    "|B02\t|10\t|490\t|65\t|Blue|\n",
    "|B03\t|10\t|560\t|35\t|Green|\n",
    "|B04\t|10\t|665\t|30\t|Red|\n",
    "|B05\t|20\t|705\t|15\t|Vegetation classification|\n",
    "|B06\t|20\t|740\t|15\t|Vegetation classification|\n",
    "|B07\t|20\t|783\t|20\t|Vegetation classification|\n",
    "|B08\t|10\t|842\t|115\t|Near infrared|\n",
    "|B08A\t|20\t|865\t|20\t|Vegetation classification|\n",
    "|B09\t|60\t|945\t|20\t|Water vapour|\n",
    "|B10\t|60\t|1375\t|30\t|Cirrus|\n",
    "|B11\t|20\t|1610\t|90\t|Snow / ice / cloud discrimination|\n",
    "|B12\t|20\t|2190\t|180\t|Snow / ice / cloud discrimination|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start mosaicing bands in C:/SS/P/20160826/ ...\n",
      "Finished mosaicing bands in C:/SS/P/20160826/ !\n",
      "All datasets mosaiced. Mosaicing finished!\n"
     ]
    }
   ],
   "source": [
    "for date_folder in folders_to_be_processed:\n",
    "    print(\"Start mosaicing bands in\", date_folder, \"...\")\n",
    "    date = date_folder[-9:-1]\n",
    "    selected_granules = [\"T31UDS\", \"T31UES\", \"T31UFS\", \"T31UGS\", \"T31UDT\", \"T31UET\", \"T31UFT\", \"T31UGT\"]\n",
    "    selected_images = []\n",
    "    B01 = []\n",
    "    B02 = []\n",
    "    B03 = []\n",
    "    B04 = []\n",
    "    B05 = []\n",
    "    B06 = []\n",
    "    B07 = []\n",
    "    B08 = []\n",
    "    B8A = []\n",
    "    B09 = []\n",
    "    B10 = []\n",
    "    B11 = []\n",
    "    B12 = []\n",
    "    overview = []\n",
    "    for path in glob(os.path.join(date_folder, \"**\", \"*.jp2\"), recursive=True):\n",
    "        for granule in selected_granules:\n",
    "            if granule in path:\n",
    "                selected_images.append(path)\n",
    "    for image in selected_images:\n",
    "        if image.endswith(\"B01.jp2\"):\n",
    "            B01.append(image)\n",
    "        elif image.endswith(\"B02.jp2\"):\n",
    "            B02.append(image)\n",
    "        elif image.endswith(\"B03.jp2\"):\n",
    "            B03.append(image)\n",
    "        elif image.endswith(\"B04.jp2\"):\n",
    "            B04.append(image)\n",
    "        elif image.endswith(\"B05.jp2\"):\n",
    "            B05.append(image)\n",
    "        elif image.endswith(\"B06.jp2\"):\n",
    "            B06.append(image)\n",
    "        elif image.endswith(\"B07.jp2\"):\n",
    "            B07.append(image)\n",
    "        elif image.endswith(\"B08.jp2\"):\n",
    "            B08.append(image)        \n",
    "        elif image.endswith(\"B8A.jp2\"):\n",
    "            B8A.append(image)\n",
    "        elif image.endswith(\"B09.jp2\"):\n",
    "            B09.append(image)\n",
    "        elif image.endswith(\"B10.jp2\"):\n",
    "            B10.append(image)        \n",
    "        elif image.endswith(\"B11.jp2\"):\n",
    "            B11.append(image)      \n",
    "        elif image.endswith(\"B12.jp2\"):\n",
    "            B12.append(image)         \n",
    "        else:\n",
    "            overview.append(image)\n",
    "    if not os.path.isdir(date_folder + \"/merged_bands\"):\n",
    "        os.mkdir(date_folder + \"/merged_bands\")\n",
    "    output_folder = date_folder + \"/merged_bands/\"\n",
    "    output_B01 = output_folder + date + \"_B01\" + \".tif\"\n",
    "    output_B02 = output_folder + date + \"_B02\" + \".tif\"\n",
    "    output_B03 = output_folder + date + \"_B03\" + \".tif\"\n",
    "    output_B04 = output_folder + date + \"_B04\" + \".tif\"\n",
    "    output_B05 = output_folder + date + \"_B05\" + \".tif\"\n",
    "    output_B06 = output_folder + date + \"_B06\" + \".tif\"\n",
    "    output_B07 = output_folder + date + \"_B07\" + \".tif\"\n",
    "    output_B08 = output_folder + date + \"_B08\" + \".tif\"\n",
    "    output_B8A = output_folder + date + \"_B8A\" + \".tif\"\n",
    "    output_B09 = output_folder + date + \"_B09\" + \".tif\"   \n",
    "    output_B10 = output_folder + date + \"_B10\" + \".tif\"\n",
    "    output_B11 = output_folder + date + \"_B11\" + \".tif\"\n",
    "    output_B12 = output_folder + date + \"_B12\" + \".tif\"\n",
    "    output_overview = output_folder + date + \"_overview\" + \".tif\"\n",
    "    gdal.Warp(destNameOrDestDS = output_B01, \n",
    "              srcDSOrSrcDSTab = B01, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)\n",
    "    gdal.Warp(destNameOrDestDS = output_B02, \n",
    "              srcDSOrSrcDSTab = B02, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)\n",
    "    gdal.Warp(destNameOrDestDS = output_B03, \n",
    "              srcDSOrSrcDSTab = B03, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)        \n",
    "    gdal.Warp(destNameOrDestDS = output_B04, \n",
    "              srcDSOrSrcDSTab = B04, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)           \n",
    "    gdal.Warp(destNameOrDestDS = output_B05, \n",
    "              srcDSOrSrcDSTab = B05, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)             \n",
    "    gdal.Warp(destNameOrDestDS = output_B06, \n",
    "              srcDSOrSrcDSTab = B06, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)\n",
    "    gdal.Warp(destNameOrDestDS = output_B07, \n",
    "              srcDSOrSrcDSTab = B07, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)\n",
    "    gdal.Warp(destNameOrDestDS = output_B08, \n",
    "              srcDSOrSrcDSTab = B08, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)\n",
    "    gdal.Warp(destNameOrDestDS = output_B8A, \n",
    "              srcDSOrSrcDSTab = B8A, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)\n",
    "    gdal.Warp(destNameOrDestDS = output_B09, \n",
    "              srcDSOrSrcDSTab = B09, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)\n",
    "    gdal.Warp(destNameOrDestDS = output_B10, \n",
    "              srcDSOrSrcDSTab = B10, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)\n",
    "    gdal.Warp(destNameOrDestDS = output_B11, \n",
    "              srcDSOrSrcDSTab = B11, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)\n",
    "    gdal.Warp(destNameOrDestDS = output_B12, \n",
    "              srcDSOrSrcDSTab = B12, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)\n",
    "    gdal.Warp(destNameOrDestDS = output_overview, \n",
    "              srcDSOrSrcDSTab = overview, \n",
    "              dstSRS = \"EPSG:4326\", \n",
    "              srcSRS = \"EPSG:32631\",\n",
    "              cropToCutline = True,\n",
    "              cutlineDSName = bounding_box_flanders)\n",
    "    print(\"Finished mosaicing bands in\", date_folder, \"!\")\n",
    "print(\"All datasets mosaiced. Mosaicing finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO DATA check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, it appears that there is no data within the Flanders bounding box. Further processing of these datasets is useless. At this stage, the processed data is checked for empty datasets. Empty datasets will be removed and excluded from further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GDAL data files not located, GDAL_DATA not set\n",
      "PROJ data files not located, PROJ_LIB not set\n",
      "GDAL data files not located, GDAL_DATA not set\n",
      "PROJ data files not located, PROJ_LIB not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processed data is checked for empty datasets. Empty datasets will be removed and excluded from further processing.\n",
      " \n",
      " \n",
      "SUMMARY\n",
      "---\n",
      "0 dataset(s) have been deleted!\n",
      "---\n",
      "Processing will continue with the following dataset(s)\n",
      "- C:/SS/P/20160826/\n"
     ]
    }
   ],
   "source": [
    "print(\"The processed data is checked for empty datasets. Empty datasets will be removed and excluded from further processing.\")\n",
    "print(\" \")\n",
    "folders_to_remove = []\n",
    "remove_count = 0\n",
    "for date_folder in folders_to_be_processed:\n",
    "    for path in glob(os.path.join(date_folder, \"*merged_bands*\", \"*B01.tif\"), recursive=True):\n",
    "        mean = zonal_stats(bounding_box_flanders, path, stats = \"mean\", nodata = 0)\n",
    "        if mean != [{'mean': None}]:\n",
    "            pass\n",
    "        else:\n",
    "            folders_to_be_processed.remove(date_folder)\n",
    "            folders_to_remove.append(date_folder)\n",
    "            remove_count = remove_count + 1\n",
    "            print(\"Imagery in\", date_folder, \"contains no data.\", date_folder, \"will be exluded from further processing and the empty data will removed from the output directory.\")\n",
    "\n",
    "for folder_to_remove in folders_to_remove:\n",
    "    shutil.rmtree(folder_to_remove)\n",
    "    \n",
    "# print statements    \n",
    "print(\" \")\n",
    "print(\"SUMMARY\")\n",
    "print(\"---\")\n",
    "print(remove_count, \"dataset(s) have been deleted!\")\n",
    "print(\"---\")\n",
    "print(\"Processing will continue with the following dataset(s)\")\n",
    "if folders_to_be_processed == []:\n",
    "    print(\"- None\")\n",
    "else:\n",
    "    for folder_to_be_processed in folders_to_be_processed:\n",
    "        print(\"-\", folder_to_be_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An RGB (Red-Green_Blue) image is created by stacking band B02 (Blue), B03 (Green) and B04 (Red) into one GeoTiff.\n",
    "- For each day, 1 RGB-images (GeoTiff) is created.\n",
    "- The output coordinatesystem is EPSG:4326.\n",
    "- The RGB image is written to a new subfolder, named \"RGB\".\n",
    "- The filename consists of the date and \"RGB\" (e.g. 20160720_RGB.tif)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start creating RGB-image for C:/SS/P/20160826/ ...\n",
      "Finished creating RGB-image for C:/SS/P/20160826/ !\n",
      "All RGB-images produced. RGB-imaging finished!\n"
     ]
    }
   ],
   "source": [
    "for date_folder in folders_to_be_processed:\n",
    "    print(\"Start creating RGB-image for\", date_folder, \"...\")\n",
    "    RGB = []\n",
    "    for path in glob(os.path.join(date_folder, \"**\", \"merged_bands\", \"*.tif\"), recursive=True):\n",
    "        if path.endswith(\"B04.tif\"):\n",
    "            RGB.append(path)\n",
    "        if path.endswith(\"B03.tif\"):\n",
    "            RGB.append(path) \n",
    "        if path.endswith(\"B02.tif\"):\n",
    "            RGB.append(path)\n",
    "    bandNamesList = [\"Red\", \"Green\", \"Blue\"]\n",
    "    if not os.path.isdir(date_folder + \"/RGB/\"):\n",
    "        os.mkdir(date_folder + \"/RGB/\")\n",
    "    date = date_folder[-9:-1]\n",
    "    outputImage = date_folder + \"/RGB/\" + date + \"_RGB.tif\"\n",
    "    gdalFormat = \"GTiff\"\n",
    "    dataType = rsgislib.TYPE_16UINT\n",
    "    imageutils.stackImageBands(RGB, bandNamesList, outputImage, None, 0, gdalFormat, dataType)\n",
    "    print(\"Finished creating RGB-image for\", date_folder, \"!\")\n",
    "print(\"All RGB-images produced. RGB-imaging finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI - Normalised Difference Vegetation Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NDVI = (NIR - R) / (NIR + R)**\n",
    "\n",
    "    NIR: Near Infra Red - Sentinelsat band 8\n",
    "    R: Visible Red - Sentinelsat band 4\n",
    "\n",
    "An NDVI image is created by performing a raster calculation using B04 (Red) and B08 (NIR), (B08 - B04) / (B08 + B04),  and writting the output to a GeoTiff.\n",
    "- For each day, 1 RGB-images (GeoTiff) is created.\n",
    "- The output coordinatesystem is EPSG:4326.\n",
    "- The NDVI image is written to a new subfolder, named \"NDVI\".\n",
    "- The filename consists of the date and \"NDVI\" (e.g. 20160720_NDVI.tif)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start creating NDVI-image for C:/SS/P/20160826/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeroen.dereu@inbo.be\\AppData\\Local\\Continuum\\Anaconda3\\envs\\osgeoenv\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating NDVI-image for C:/SS/P/20160826/ !\n",
      "All NDVI-images produced. NDVI-imaging finished!\n"
     ]
    }
   ],
   "source": [
    "for date_folder in folders_to_be_processed:\n",
    "    print(\"Start creating NDVI-image for\", date_folder, \"...\")\n",
    "    for path in glob(os.path.join(date_folder, \"**\", \"merged_bands\", \"*tif\"), recursive=True):\n",
    "        if path.endswith(\"B04.tif\"):\n",
    "            B04 = gdal.Open(path)\n",
    "        if path.endswith(\"B08.tif\"):\n",
    "            B08 = gdal.Open(path)\n",
    "    red = B04.ReadAsArray()\n",
    "    nir = B08.ReadAsArray()\n",
    "    check = np.logical_and(red > 0, nir > 0)\n",
    "    ndvi = np.where(check, (nir - red) / (nir + red), -999)\n",
    "    geo = B08.GetGeoTransform()\n",
    "    proj = B08.GetProjection()\n",
    "    shape = red.shape\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    # define output filename and location\n",
    "    if not os.path.isdir(date_folder + \"/NDVI/\"):\n",
    "        os.mkdir(date_folder + \"/NDVI/\")\n",
    "    date = date_folder[-9:-1]\n",
    "    ndvi_file = date_folder + \"/NDVI/\" + date + \"_ndvi.tif\"\n",
    "    # create and write the nvdi-file\n",
    "    dst_ds = driver.Create(ndvi_file, shape[1], shape[0], 1, gdal.GDT_Float32)\n",
    "    dst_ds.SetGeoTransform(geo)\n",
    "    dst_ds.SetProjection(proj)\n",
    "    dst_ds.GetRasterBand(1).WriteArray(ndvi)\n",
    "    dst_ds = None\n",
    "    B04 = None\n",
    "    B08 = None\n",
    "    print(\"Finished creating NDVI-image for\", date_folder, \"!\")\n",
    "print(\"All NDVI-images produced. NDVI-imaging finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DATA MANAGEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The last step is a data managment step:\n",
    "- The raw data is removed from the directory, only the processing output is kept.\n",
    "- The processed data is moved to the output directory.\n",
    "- The now empty processing directory is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start data managment procedure...\n",
      "All processing output moved to C:/SS\n",
      "Data management procedure done!\n",
      "Check C:/SS for processing output.\n",
      "Process finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"Start data managment procedure...\")\n",
    "# The raw data is removed from the directory.\n",
    "for path in glob(os.path.join(processing_dir, \"**\", \"S2A*.SAFE\"), recursive=True):\n",
    "    shutil.rmtree(path)\n",
    "    \n",
    "# The processed data is moved to the output directory.\n",
    "for processed_dataset in os.listdir(processing_dir):\n",
    "    processed_dataset_folder = processing_dir + \"/\" + processed_dataset\n",
    "    shutil.move(src = processed_dataset_folder, dst = output_dir)\n",
    "print(\"All processing output moved to\", output_dir)\n",
    "\n",
    "# The now empty processing directory, named \"P\", is removed.\n",
    "shutil.rmtree(processing_dir)\n",
    "\n",
    "print(\"Data management procedure done!\")\n",
    "print(\"Check\", output_dir, \"for processing output.\")\n",
    "print(\"Process finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
